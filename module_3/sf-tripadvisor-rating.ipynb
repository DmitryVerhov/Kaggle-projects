{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\nimport collections\nimport re\nimport datetime\nfrom datetime import datetime \nimport json\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fixing RANDOM_SEED and package version:\nRANDOM_SEED = 42\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_of_rating(number):\n    # Округляем до 0.5\n    return np.round(number * 2) / 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nworld_cities = pd.read_csv('/kaggle/input/worldcities/worldcities.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()\ndf_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()\ndf_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()\nsample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine train and test to make the common stucture:\ndf_train['sample'] = 1 # Marking train \ndf_test['sample'] = 0 # Marking test \ndf_test['Rating'] = 0 # And add Rating to test filling it with zeroes\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # Combine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()\ndata.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"world_cities.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data\n"},{"metadata":{},"cell_type":"markdown","source":"## 1. Working with NAN \n"},{"metadata":{},"cell_type":"markdown","source":"# ***Number of Reviews***\n\nThere is NaN values in 'Number of Reviews', but we can see, that there is some reviews in 'Reviews' column near:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[(data['Number of Reviews'].isna()) & (data['Reviews'] !='[[], []]')].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's inplace such NaN's with mean values for each city:\n\ncities = data['City'].unique().tolist()# cities list\n\nfor i in cities:\n    data['Number of Reviews'] = data['Number of Reviews'].mask( \n            (data['Number of Reviews'].isna()) & #Find null values\n            (data['Reviews'] != '[[], []]') & #With filled reviews  \n            (data['City'] == i), #For each city in cities \n            # Enter mean value for the city:\n            data['Number of Reviews'][data['City'] == i].mean()\n                                \n     ) \n\n# Replace NaN's with zeroes:\ndata['Number of Reviews'].fillna(0, inplace=True)\n# It is a real value, so I'll make it integer:\ndata['Number of Reviews'] = data['Number of Reviews'].apply(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if I missed values for NaN in ['Reviews']:\ndata['Number of Reviews'][data.Reviews.isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# *Reviews*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill NaN's with '[[], []]'\ndata['Reviews'] = data['Reviews'].fillna('[[], []]')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Cuisine Style***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill NaN's with '['Other']'\ndata['Cuisine Style'] = data['Cuisine Style'].fillna(\"['other']\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***Price Range***"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill NaN's with zeroes:\ndata['Price Range'].fillna(0, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if we missed some NaN's: \ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **2. Working with features**"},{"metadata":{},"cell_type":"markdown","source":"**Restaurant_id**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Restaurant_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Maybe _id depends on ranking, so it will be usefull to make it numeric: \ndef change_id(x):\n    if 'id_' in str(x):\n        return str(x).replace('id_', '')\n    else: return x\n    \ndata['Restaurant_id'] = data['Restaurant_id'].apply(change_id)\ndata['Restaurant_id'] = pd.to_numeric(data['Restaurant_id'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Cuisine Style**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Making correct lists:\ndata['Cuisine Style'] = data['Cuisine Style'].apply(\n    lambda x: re.findall('\\w+\\s*\\w+\\s*\\w+', str(x))\n     )\ndata['Cuisine Style'].sample(5) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Price Range**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's fill the values by the dictionary:\nprice_dict = {'$':1,'$$ - $$$':2,'$$$$':3}\ndata['Price Range']=data['Price Range'].map(lambda x: price_dict.get(x,x))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick out the dates: \ndata['Review_date'] = data.Reviews.apply(lambda x : [0] if pd.isna(x) else x[2:-2].split('], [')[1][1:-1].split(\"', '\"))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ***New Features***"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of all cuisines:\ncuisines = set()\n\nfor i in data['Cuisine Style']:\n    for j in i:\n        cuisines.add(j)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency of occurrence:\ntype_cousine = {}  # Creating the dictionary to store the info:\n\nfor item in cuisines:  # Iterating over the list of cuisines\n    type_cousine[item] = 0 # Add the keys for each cuisine\n\nfor i in data['Cuisine Style']:   # Iterating over the ['Cuisine Style']\n    for j in i:   # Look into the list of cuisines in each restaurant\n        type_cousine[j] += 1   # increase the value of the required key by 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_cousine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The top of cuisines:\ntop_cuisine = []\nfor key, value in type_cousine.items():\n    if value > 3000:\n        top_cuisine.append(key)\ntop_cuisine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# With this function we will find out if our restaurant has the popular cuisine:\n\ndef most_popular_cuisine(x):\n    \n    for element in top_cuisine:\n        if element in x:\n            return 1\n        else:\n            continue\n            \n\n# Create the new column:           \ndata['most_popular_cuisine'] = data['Cuisine Style'].apply(most_popular_cuisine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['most_popular_cuisine'].fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add a new feature \"Number of cuisines in a restaurant\"\ndata['cuisine_counts'] = data['Cuisine Style'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Review dates**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we will find how many days have gone from the last review:\n\n# Max date in cell:\ndata['max_date'] = pd.to_datetime(data['Review_date'].apply(lambda x: max(x)))\n\n# New column:\ndata['days_ago'] = (datetime.now() - data['max_date']).apply(lambda x: x.days)\ndata.days_ago.fillna(data.days_ago.mean(), inplace=True)\ndata.days_ago = data.days_ago.apply(int)# Make it integer \ndata.drop(['Review_date','max_date'], axis=1, inplace=True, errors='ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Population of the City**"},{"metadata":{"trusted":true},"cell_type":"code","source":"population_dict = {\n    'London' : 0,'Paris' : 0, 'Madrid' : 0, 'Barcelona' : 0,'Berlin' : 0, 'Milan' : 0, \n    'Rome' : 0, 'Prague' : 0, 'Lisbon' : 0,'Vienna' : 0, 'Amsterdam' : 0, 'Brussels' : 0,                         \n    'Hamburg' : 0,'Munich' : 0, 'Lyon' : 0, 'Stockholm' : 0, 'Budapest' : 0, 'Warsaw' : 0, \n    'Dublin' : 0, 'Copenhagen' : 0, 'Athens' : 0, 'Edinburgh' : 0, 'Zurich' : 0,'Oporto' : 0, \n    'Geneva' : 0, 'Krakow' : 0, 'Oslo' : 0, 'Helsinki' : 0, 'Bratislava' : 0, \n    'Luxembourg' : 0,'Ljubljana' : 0}\n\nfor c in population_dict.keys():# Entering values from dataset\n    population_dict[c] = world_cities.population[world_cities.city == c].max()\n\n#Fill missing values from Google:\npopulation_dict['Zurich'] = 402.762\npopulation_dict['Oporto'] = 214.349 \npopulation_dict['Krakow'] = 780.000\n# Create new column\ndata['population'] = data.apply(lambda row: population_dict[row['City']], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"City"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's make new columns for each city\ncity_name=pd.get_dummies(data.City)    \ndata = pd.concat((data,city_name),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's draw the correlation plot\ncorrelation = data[data['sample'] == 1][['Ranking', 'Price Range','Number of Reviews', 'Rating','most_popular_cuisine', \n                                         'cuisine_counts', 'days_ago', 'population']].corr()\nplt.figure(figsize=(20, 10))\nsns.heatmap(correlation, annot=True, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is a large correlation between population/Ranking and Price/cuisine counts. \nWe must do something with it(maybe drop later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build Ranking plot:\nplt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"There are many reustaurants with Ranking under 2500"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see for the value of reustaurants for each city\ndf_train['City'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The distribution of 'Ranking' in London:\ndf_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 Cities:\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It seems like we have a normal distribution of 'Ranking' in each City, so it needs to be standardized. "},{"metadata":{},"cell_type":"markdown","source":"### The distribution of target variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# And now we will standardize Ranking:\nmn = data.groupby('City')['Ranking'].mean()\nst = data.groupby('City')['Ranking'].std()\ndata['Std_Ranking'] = (data['Ranking'] - data['City'].map(mn))/data['City'].map(st)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(['Restaurant_id','Cuisine Style', 'Reviews', 'ID_TA', \n           'City','Ranking','URL_TA'], axis=1, inplace=True, errors='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = round_of_rating(model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = round_of_rating(model.predict(test_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}